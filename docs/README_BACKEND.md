# Backend Documentation - Job Match System

## ğŸ“– Overview

This is a **FastAPI-based backend** for an AI-powered job matching system that uses **semantic embeddings** and **skill matching** to rank candidates against job descriptions.

## ğŸ¯ What It Does

1. **User Management**: Registration, login, JWT authentication
2. **Job Management**: Create, update, delete job postings
3. **Resume Processing**: Upload, parse, extract skills from PDF/DOCX
4. **AI Matching**: Generate embeddings, calculate similarity, match skills
5. **Candidate Ranking**: Rank candidates by match score
6. **Interview Scheduling**: Schedule and manage interviews
7. **Analytics**: Track recruitment metrics

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         API Layer (FastAPI)         â”‚  â† HTTP endpoints
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Service Layer (Business)       â”‚  â† AI, matching, parsing
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Repository Layer (Data Access)    â”‚  â† Database operations
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Model Layer (SQLAlchemy)        â”‚  â† Database schema
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Documentation Files

| File | Description |
|------|-------------|
| **BACKEND_ARCHITECTURE.md** | Complete architecture, flow diagrams, detailed explanations |
| **BACKEND_QUICK_REFERENCE.md** | Quick lookup for libraries, endpoints, commands |
| **README_BACKEND.md** | This file - overview and getting started |

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
cd backend
pip install -r requirements.txt
```

### 2. Set Up Environment
```bash
cp .env.example .env
# Edit .env with your database URL, Redis URL, etc.
```

### 3. Run Migrations
```bash
alembic upgrade head
```

### 4. Start Server
```bash
uvicorn app.main:app --reload
```

Server runs at: `http://localhost:8000`
API docs at: `http://localhost:8000/docs`

## ğŸ”‘ Key Technologies

### Core Framework
- **FastAPI** - Modern async web framework
- **Uvicorn** - ASGI server
- **Pydantic** - Data validation

### Database
- **PostgreSQL** - Main database
- **pgvector** - Vector similarity search
- **SQLAlchemy 2.0** - Async ORM
- **Alembic** - Migrations

### AI/ML
- **sentence-transformers** - Generate embeddings (384-dim)
- **PyTorch (CPU)** - ML framework
- **numpy** - Vector operations

### Caching & Auth
- **Redis** - Cache embeddings and results
- **python-jose** - JWT tokens
- **passlib** - Password hashing (bcrypt)

### Document Processing
- **PyPDF2** - PDF extraction
- **python-docx** - DOCX extraction
- **pdfminer.six** - Advanced PDF parsing

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/v1/endpoints/     # API routes
â”‚   â”‚   â”œâ”€â”€ auth.py          # Registration, login
â”‚   â”‚   â”œâ”€â”€ jobs.py          # Job CRUD
â”‚   â”‚   â”œâ”€â”€ resumes.py       # Resume upload
â”‚   â”‚   â”œâ”€â”€ matching.py      # Matching logic
â”‚   â”‚   â””â”€â”€ interviews.py    # Interview scheduling
â”‚   â”œâ”€â”€ core/                # Core functionality
â”‚   â”‚   â”œâ”€â”€ config.py        # Settings
â”‚   â”‚   â”œâ”€â”€ security.py      # JWT, passwords
â”‚   â”‚   â””â”€â”€ deps.py          # Dependencies
â”‚   â”œâ”€â”€ models/              # Database models
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ job.py
â”‚   â”‚   â”œâ”€â”€ resume.py
â”‚   â”‚   â””â”€â”€ match_result.py
â”‚   â”œâ”€â”€ repositories/        # Data access
â”‚   â”œâ”€â”€ schemas/             # Pydantic schemas
â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â”œâ”€â”€ matching_engine.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â””â”€â”€ skill_extraction_service.py
â”‚   â””â”€â”€ main.py             # FastAPI app
â”œâ”€â”€ alembic/                # Database migrations
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ .env                    # Configuration
```

## ğŸ”„ Complete Flow: User Registration â†’ Job Matching

### 1. User Registers
```
POST /api/v1/auth/register
{email, password, full_name, role, company_name}
  â†“
Hash password with bcrypt
  â†“
Store in database
  â†“
Return user object
```

### 2. User Logs In
```
POST /api/v1/auth/login
{email, password}
  â†“
Verify password
  â†“
Generate JWT token
  â†“
Return {access_token, user}
```

### 3. Create Job
```
POST /api/v1/jobs (with JWT token)
{title, company, description, requirements, skills_required}
  â†“
Store job in database
  â†“
Generate embedding (384-dim vector)
  â†“
Store embedding in pgvector column
  â†“
Return job with embedding
```

### 4. Upload Resume
```
POST /api/v1/resumes/upload
{file: resume.pdf, job_id}
  â†“
Extract text from PDF/DOCX
  â†“
Parse sections (experience, skills, education)
  â†“
Extract skills (pattern matching)
  â†“
Generate embedding (384-dim vector)
  â†“
Store resume with embedding
  â†“
**AUTO-MATCH** to job
```

### 5. Matching Process (Automatic)
```
Get job embedding and resume embedding
  â†“
Calculate cosine similarity (pgvector)
  â†“
Match skills (required vs extracted)
  â†“
Calculate overall score:
  overall = (similarity * 0.6) + (skill_match * 0.4)
  â†“
Generate explanation (template-based)
  â†“
Store match_result with score and status=PENDING
  â†“
Return match result
```

### 6. View Candidates
```
GET /api/v1/jobs/{job_id}/candidates
  â†“
Query match_results JOIN resumes
  â†“
Sort by match_score DESC
  â†“
Return ranked list of candidates
```

### 7. Update Candidate Status
```
PATCH /api/v1/jobs/{job_id}/candidates/{resume_id}
{status: "shortlisted"}
  â†“
Update match_result.status
  â†“
Return updated result
```

### 8. Schedule Interview
```
POST /api/v1/interviews
{resume_id, job_id, interview_type, scheduled_at}
  â†“
Validate: candidate not rejected
  â†“
Store interview
  â†“
Return interview details
```

## ğŸ§  How AI Matching Works

### Step 1: Generate Embeddings
- Uses **SentenceTransformer** model: `all-MiniLM-L6-v2`
- Converts text to **384-dimensional vector**
- Captures semantic meaning

```python
job_text = f"{title} {description} {requirements}"
job_embedding = model.encode(job_text)  # [0.123, -0.456, ...]
```

### Step 2: Calculate Similarity
- Uses **cosine similarity** via pgvector
- Compares job embedding vs resume embedding
- Returns score 0-1 (0=different, 1=identical)

```sql
SELECT resume_id, 
       1 - (job.embedding <=> resume.embedding) as similarity
FROM resumes
ORDER BY similarity DESC
```

### Step 3: Match Skills
- Extracts skills from job requirements
- Extracts skills from resume
- Calculates: matched, missing, additional skills
- Returns skill match percentage

### Step 4: Calculate Overall Score
```python
overall_score = (similarity_score * 0.6) + (skill_match_percentage * 0.4)
```

### Step 5: Generate Explanation
- Uses **template-based** approach (no AI API calls)
- Fills in: score, matched skills, missing skills
- Fast and cost-effective

## ğŸ—„ï¸ Database Schema

### Key Tables

**users** - Authentication
- id, email, hashed_password, role, company_id

**job_descriptions** - Job postings
- id, title, description, requirements, skills_required
- **embedding** (vector(384)) â† Semantic vector

**resumes** - Candidate resumes
- id, candidate_name, email, content, extracted_skills
- **embedding** (vector(384)) â† Semantic vector

**match_results** - Job-resume matches
- job_id, resume_id, match_score, explanation
- key_strengths, missing_skills, **status**
- UNIQUE(job_id, resume_id) â† Prevent duplicates

**interviews** - Interview scheduling
- resume_id, job_id, interview_type, scheduled_at, status

## ğŸ” Authentication

- **JWT tokens** for authentication
- **Bcrypt** for password hashing
- **Bearer token** in Authorization header
- Token expires after 30 minutes (configurable)

## âš¡ Performance Features

- âœ… **Async/await** - Non-blocking I/O
- âœ… **Redis caching** - Cache embeddings and results
- âœ… **Connection pooling** - Reuse DB connections
- âœ… **Vector indexing** - Fast similarity search with IVFFlat
- âœ… **Batch processing** - Generate multiple embeddings at once
- âœ… **Circuit breaker** - Prevent cascading failures

## ğŸ“Š API Documentation

Interactive API docs available at:
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app

# Run specific test file
pytest tests/test_auth.py
```

## ğŸ”§ Configuration

Key environment variables:

```bash
# Database
DATABASE_URL=postgresql+asyncpg://user:pass@host:5432/dbname

# Redis
REDIS_URL=redis://localhost:6379

# Security
SECRET_KEY=your-secret-key-here
ACCESS_TOKEN_EXPIRE_MINUTES=30

# AI (optional)
ANTHROPIC_API_KEY=sk-...

# Environment
ENVIRONMENT=development
```

## ğŸ“ˆ Monitoring

- **Health check**: `GET /api/v1/health`
- **Logs**: Structured JSON logs in `backend/logs/`
- **Metrics**: Request duration, DB query time
- **Errors**: Centralized error handling

## ğŸš¢ Deployment

See deployment guides:
- **RAILWAY_DEPLOYMENT.md** - Deploy to Railway
- **DEPLOYMENT_OPTIONS.md** - Compare platforms
- **QUICK_DEPLOY.md** - Quick start guide

## ğŸ“š Learn More

- **BACKEND_ARCHITECTURE.md** - Deep dive into architecture
- **BACKEND_QUICK_REFERENCE.md** - Quick lookup reference
- **API Docs** - `http://localhost:8000/docs`

## ğŸ¤ Contributing

1. Create feature branch
2. Make changes
3. Run tests
4. Submit pull request

## ğŸ“ Notes

- **No Spacy**: Uses pattern matching instead (saves ~200MB)
- **CPU-only PyTorch**: Optimized for deployment (saves ~500MB)
- **Template explanations**: No AI API calls (fast and free)
- **Auto-matching**: Resumes matched automatically on upload
- **Duplicate prevention**: UNIQUE constraint prevents duplicate matches

---

**Ready to explore?** Start with `BACKEND_ARCHITECTURE.md` for detailed flow diagrams! ğŸš€

